{"id": "2511.02132", "categories": ["cs.AR", "cs.DC", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.02132", "abs": "https://arxiv.org/abs/2511.02132", "authors": ["Mansi Choudhary", "Karthik Sangaiah", "Sonali Singh", "Muhammad Osama", "Lisa Wu Wills", "Ganesh Dasika"], "title": "Optimizing Attention on GPUs by Exploiting GPU Architectural NUMA Effects", "comment": "11 pages, 14 figures", "summary": "The rise of disaggregated AI GPUs has exposed a critical bottleneck in\nlarge-scale attention workloads: non-uniform memory access (NUMA). As\nmulti-chiplet designs become the norm for scaling compute capabilities, memory\nlatency and bandwidth vary sharply across compute regions, undermining the\nperformance of traditional GPU kernel scheduling strategies that assume uniform\nmemory access. We identify how these NUMA effects distort locality in\nmulti-head attention (MHA) and present Swizzled Head-first Mapping, a\nspatially-aware scheduling strategy that aligns attention heads with GPU NUMA\ndomains to exploit intra-chiplet cache reuse. On AMD's MI300X architecture, our\nmethod achieves up to 50% higher performance over state-of-the-art attention\nalgorithms using conventional scheduling techniques and sustains consistently\nhigh L2 cache hit rates of 80-97%. These results demonstrate that NUMA-aware\nscheduling is now fundamental to achieving full efficiency on next-generation\ndisaggregated GPUs, offering a path forward for scalable AI training and\ninference.", "AI": {"tldr": "\u9488\u5bf9\u5206\u89e3\u5f0fAI GPU\u4e2d\u7684NUMA\u74f6\u9888\uff0c\u63d0\u51fa\u4e86Swizzled Head-first Mapping\u8c03\u5ea6\u7b56\u7565\uff0c\u5728AMD MI300X\u4e0a\u5b9e\u73b0\u6027\u80fd\u63d0\u534750%\uff0cL2\u7f13\u5b58\u547d\u4e2d\u7387\u8fbe80-97%", "motivation": "\u5206\u89e3\u5f0fAI GPU\u8bbe\u8ba1\u4e2d\u51fa\u73b0\u7684\u975e\u7edf\u4e00\u5185\u5b58\u8bbf\u95ee(NUMA)\u95ee\u9898\u5df2\u6210\u4e3a\u5927\u89c4\u6a21\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u5173\u952e\u74f6\u9888\uff0c\u4f20\u7edfGPU\u8c03\u5ea6\u7b56\u7565\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8de8\u8ba1\u7b97\u533a\u57df\u7684\u5185\u5b58\u5ef6\u8fdf\u5dee\u5f02", "method": "\u63d0\u51faSwizzled Head-first Mapping\u7a7a\u95f4\u611f\u77e5\u8c03\u5ea6\u7b56\u7565\uff0c\u5c06\u6ce8\u610f\u529b\u5934\u4e0eGPU NUMA\u57df\u5bf9\u9f50\uff0c\u5229\u7528\u82af\u7247\u5185\u7f13\u5b58\u91cd\u7528", "result": "\u5728AMD MI300X\u67b6\u6784\u4e0a\uff0c\u76f8\u6bd4\u4f20\u7edf\u8c03\u5ea6\u6280\u672f\uff0c\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe50%\uff0cL2\u7f13\u5b58\u547d\u4e2d\u7387\u7a33\u5b9a\u572880-97%", "conclusion": "NUMA\u611f\u77e5\u8c03\u5ea6\u5bf9\u4e0b\u4e00\u4ee3\u5206\u89e3\u5f0fGPU\u5b9e\u73b0\u5168\u6548\u8fd0\u884c\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u53ef\u6269\u5c55AI\u8bad\u7ec3\u548c\u63a8\u7406\u63d0\u4f9b\u4e86\u524d\u8fdb\u8def\u5f84"}}
{"id": "2511.02269", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.02269", "abs": "https://arxiv.org/abs/2511.02269", "authors": ["Takuto Ando", "Yu Eto", "Ayumu Takeuchi", "Yasuhiko Nakashima"], "title": "Energy-Efficient Hardware Acceleration of Whisper ASR on a CGLA", "comment": "This paper is accepted at The Thirteenth International Symposium on\n  Computing and Networking (CANDAR2025)", "summary": "The rise of generative AI for tasks like Automatic Speech Recognition (ASR)\nhas created a critical energy consumption challenge. While ASICs offer high\nefficiency, they lack the programmability to adapt to evolving algorithms. To\naddress this trade-off, we implement and evaluate Whisper's core computational\nkernel on the IMAX, a general-purpose Coarse-Grained Linear Arrays (CGLAs)\naccelerator. To our knowledge, this is the first work to execute a Whisper\nkernel on a CGRA and compare its performance against CPUs and GPUs. Using\nhardware/software co-design, we evaluate our system via an FPGA prototype and\nproject performance for a 28 nm ASIC. Our results demonstrate superior energy\nefficiency. The projected ASIC is 1.90x more energy-efficient than the NVIDIA\nJetson AGX Orin and 9.83x more than an NVIDIA RTX 4090 for the Q8_0 model. This\nwork positions CGLA as a promising platform for sustainable ASR on\npower-constrained edge devices.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728CGLA\u4e0a\u5b9e\u73b0\u4e86Whisper\u6838\u5fc3\u8ba1\u7b97\u5185\u6838\uff0c\u5e76\u901a\u8fc7FPGA\u539f\u578b\u8bc4\u4f30\u548c28nm ASIC\u6027\u80fd\u9884\u6d4b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u80fd\u6548\u65b9\u9762\u4f18\u4e8eCPU\u548cGPU\uff0c\u4e3a\u529f\u8017\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4e86\u53ef\u6301\u7eed\u7684ASR\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u5174\u8d77\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u80fd\u8017\u6311\u6218\uff0cASIC\u867d\u7136\u9ad8\u6548\u4f46\u7f3a\u4e4f\u7b97\u6cd5\u9002\u5e94\u6027\uff0c\u9700\u8981\u5bfb\u627e\u517c\u987e\u80fd\u6548\u548c\u53ef\u7f16\u7a0b\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728IMAX CGLA\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0Whisper\u6838\u5fc3\u8ba1\u7b97\u5185\u6838\uff0c\u91c7\u7528\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7FPGA\u539f\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u9884\u6d4b28nm ASIC\u7684\u6027\u80fd\u3002", "result": "\u6295\u5f71\u7684ASIC\u5728Q8_0\u6a21\u578b\u4e0a\u6bd4NVIDIA Jetson AGX Orin\u80fd\u6548\u9ad81.90\u500d\uff0c\u6bd4NVIDIA RTX 4090\u9ad89.83\u500d\u3002", "conclusion": "CGLA\u662f\u529f\u8017\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u53ef\u6301\u7eedASR\u7684\u6709\u524d\u666f\u5e73\u53f0\uff0c\u5728\u80fd\u6548\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edfCPU\u548cGPU\u65b9\u6848\u3002"}}
{"id": "2511.02285", "categories": ["cs.AR", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02285", "abs": "https://arxiv.org/abs/2511.02285", "authors": ["Zhuorui Zhao", "Bing Li", "Grace Li Zhang", "Ulf Schlichtmann"], "title": "VFocus: Better Verilog Generation from Large Language Model via Focused Reasoning", "comment": "accepted by SOCC 2025", "summary": "Large Language Models (LLMs) have shown impressive potential in generating\nVerilog codes, but ensuring functional correctness remains a challenge.\nExisting approaches often rely on self-consistency or simulation feedback to\nselect the best candidate, but they miss opportunities to focus LLM reasoning\non the most informative parts of the design. We propose VFocus, a three-stage\nframework that enhances Verilog generation by sharpening the focus of LLM\nreasoning onto critical decision points in the code generation process. In the\n\\textbf{pre-ranking stage}, VFocus generates multiple code candidates through\nLLM prompting, retries for syntactically valid outputs, and introduces a\n\\textit{Density-guided Filtering} to retain candidates that fall within the\n\"reasoning sweet spot\" for functional correctness. In the \\textbf{ranking\nstage}, we simulate each code candidate using an automatically generated\ntestbench and apply self-consistency-based clustering to identify the most\nconsistent outputs. Finally, in the \\textbf{post-ranking refinement stage},\nVFocus performs inconsistency mining on top-ranked candidates and invokes\nreasoning-augmented LLM prompts for candidate refinement. Experiments on the\nVerilogEval-Human benchmark show that VFocus significantly improves the pass@1\ncorrectness across multiple reasoning LLMs, demonstrating its effectiveness in\nenhancing Verilog generation for complex hardware design tasks.", "AI": {"tldr": "VFocus\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u7126LLM\u63a8\u7406\u4e8e\u5173\u952e\u51b3\u7b56\u70b9\u6765\u589e\u5f3aVerilog\u4ee3\u7801\u751f\u6210\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5728VerilogEval-Human\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86pass@1\u6b63\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u81ea\u4e00\u81f4\u6027\u6216\u4eff\u771f\u53cd\u9988\u9009\u62e9\u6700\u4f73\u5019\u9009\uff0c\u4f46\u672a\u80fd\u5c06LLM\u63a8\u7406\u805a\u7126\u4e8e\u8bbe\u8ba1\u4e2d\u6700\u5177\u4fe1\u606f\u91cf\u7684\u90e8\u5206\uff0c\u5bfc\u81f4\u529f\u80fd\u6b63\u786e\u6027\u9a8c\u8bc1\u5b58\u5728\u6311\u6218\u3002", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u9884\u6392\u5e8f\u9636\u6bb5\u751f\u6210\u4ee3\u7801\u5019\u9009\u5e76\u8fc7\u6ee4\uff1b\u6392\u5e8f\u9636\u6bb5\u4eff\u771f\u6d4b\u8bd5\u5e76\u805a\u7c7b\u8bc6\u522b\u4e00\u81f4\u8f93\u51fa\uff1b\u540e\u6392\u5e8f\u7cbe\u70bc\u9636\u6bb5\u6316\u6398\u4e0d\u4e00\u81f4\u6027\u5e76\u8c03\u7528\u63a8\u7406\u589e\u5f3aLLM\u63d0\u793a\u8fdb\u884c\u5019\u9009\u7cbe\u70bc\u3002", "result": "\u5728VerilogEval-Human\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVFocus\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u4e2a\u63a8\u7406LLM\u7684pass@1\u6b63\u786e\u7387\u3002", "conclusion": "VFocus\u901a\u8fc7\u805a\u7126LLM\u63a8\u7406\u4e8e\u5173\u952e\u51b3\u7b56\u70b9\uff0c\u6709\u6548\u63d0\u5347\u4e86\u590d\u6742\u786c\u4ef6\u8bbe\u8ba1\u4efb\u52a1\u4e2dVerilog\u751f\u6210\u7684\u529f\u80fd\u6b63\u786e\u6027\u3002"}}
{"id": "2511.02408", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.02408", "abs": "https://arxiv.org/abs/2511.02408", "authors": ["Takuto Ando", "Yusuke Inoue"], "title": "Facial Expression Recognition System Using DNN Accelerator with Multi-threading on FPGA", "comment": "This paper was published in the proceedings of the 2024 Twelfth\n  International Symposium on Computing and Networking Workshops (CANDARW)", "summary": "In this paper, we implement a stand-alone facial expression recognition\nsystem on an SoC FPGA with multi-threading using a Deep learning Processor Unit\n(DPU). The system consists of two steps: one for face detection step and one\nfor facial expression recognition. In the previous work, the Haar Cascade\ndetector was run on a CPU in the face detection step due to FPGA resource\nlimitations, but this detector is less accurate for profile and variable\nillumination condition images. Moreover, the previous work used a dedicated\ncircuit accelerator, so running a second DNN inference for face detection on\nthe FPGA would require the addition of a new accelerator. As an alternative to\nthis approach, we run the two inferences by DNN on a DPU, which is a\ngeneral-purpose CNN accelerator of the systolic array type. Our method for face\ndetection using DenseBox and facial expression recognition using CNN on the\nsame DPU enables the efficient use of FPGA resources while maintaining a small\ncircuit size. We also developed a multi-threading technique that improves the\noverall throughput while increasing the DPU utilization efficiency. With this\napproach, we achieved an overall system throughput of 25 FPS and a throughput\nper power consumption of 2.4 times.", "AI": {"tldr": "\u5728SoC FPGA\u4e0a\u5b9e\u73b0\u57fa\u4e8eDPU\u7684\u591a\u7ebf\u7a0b\u4eba\u8138\u8868\u60c5\u8bc6\u522b\u7cfb\u7edf\uff0c\u4f7f\u7528DenseBox\u8fdb\u884c\u4eba\u8138\u68c0\u6d4b\u548cCNN\u8fdb\u884c\u8868\u60c5\u8bc6\u522b\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\uff0c\u8fbe\u523025FPS\u7cfb\u7edf\u541e\u5410\u91cf\u548c2.4\u500d\u80fd\u6548\u6bd4", "motivation": "\u89e3\u51b3\u4f20\u7edfHaar Cascade\u4eba\u8138\u68c0\u6d4b\u5668\u5728\u4fa7\u8138\u548c\u53d8\u5149\u7167\u6761\u4ef6\u4e0b\u51c6\u786e\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u4e3a\u7b2c\u4e8c\u4e2aDNN\u63a8\u7406\u6dfb\u52a0\u4e13\u7528\u52a0\u901f\u5668\uff0c\u5b9e\u73b0FPGA\u8d44\u6e90\u7684\u9ad8\u6548\u5229\u7528", "method": "\u4f7f\u7528DPU\uff08\u8109\u52a8\u9635\u5217\u578b\u901a\u7528CNN\u52a0\u901f\u5668\uff09\u540c\u65f6\u8fd0\u884cDenseBox\u4eba\u8138\u68c0\u6d4b\u548cCNN\u8868\u60c5\u8bc6\u522b\u4e24\u4e2aDNN\u63a8\u7406\uff0c\u5f00\u53d1\u591a\u7ebf\u7a0b\u6280\u672f\u63d0\u9ad8DPU\u5229\u7528\u7387\u548c\u7cfb\u7edf\u541e\u5410\u91cf", "result": "\u7cfb\u7edf\u6574\u4f53\u541e\u5410\u91cf\u8fbe\u523025FPS\uff0c\u5355\u4f4d\u529f\u8017\u541e\u5410\u91cf\u63d0\u53472.4\u500d\uff0c\u5b9e\u73b0\u4e86\u5728FPGA\u4e0a\u7684\u9ad8\u6548\u4eba\u8138\u8868\u60c5\u8bc6\u522b", "conclusion": "\u57fa\u4e8eDPU\u7684\u591a\u7ebf\u7a0b\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u5c0f\u7535\u8def\u89c4\u6a21\u7684\u540c\u65f6\u6709\u6548\u5229\u7528FPGA\u8d44\u6e90\uff0c\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6027\u80fd\u7684\u4eba\u8138\u8868\u60c5\u8bc6\u522b\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.02494", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.02494", "abs": "https://arxiv.org/abs/2511.02494", "authors": ["Raul Murillo", "Julio Villalba-Moreno", "Alberto A. Del Barrio", "Guillermo Botella"], "title": "Digit-Recurrence Posit Division", "comment": "11 pages, 9 figures", "summary": "Posit arithmetic has emerged as a promising alternative to IEEE 754\nfloating-point representation, offering enhanced accuracy and dynamic range.\nHowever, division operations in posit systems remain challenging due to their\ninherent hardware complexity. In this work, we present posit division units\nbased on the digit-recurrence algorithm, marking the first implementation of\nradix-4 digit-recurrence techniques within this context. Our approach\nincorporates hardware-centric optimizations including redundant arithmetic,\non-the-fly quotient conversion, and operand scaling to streamline the division\nprocess while mitigating latency, area, and power overheads. Comprehensive\nsynthesis evaluations across multiple posit configurations demonstrate\nsignificant performance improvements, including more than 80% energy reduction\nwith small area overhead compared to existing methods, and a substantial\ndecrease in the number of iterations. These results underscore the potential of\nour adapted algorithm to enhance the efficiency of posit-based arithmetic\nunits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6570\u5b57\u9012\u5f52\u7b97\u6cd5\u7684posit\u9664\u6cd5\u5355\u5143\uff0c\u9996\u6b21\u5728\u8be5\u9886\u57df\u5b9e\u73b0radix-4\u6570\u5b57\u9012\u5f52\u6280\u672f\uff0c\u901a\u8fc7\u786c\u4ef6\u4f18\u5316\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u8fed\u4ee3\u6b21\u6570\u3002", "motivation": "Posit\u7b97\u672f\u4f5c\u4e3aIEEE 754\u6d6e\u70b9\u8868\u793a\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u52a8\u6001\u8303\u56f4\uff0c\u4f46\u5176\u9664\u6cd5\u64cd\u4f5c\u56e0\u786c\u4ef6\u590d\u6742\u6027\u800c\u9762\u4e34\u6311\u6218\u3002", "method": "\u91c7\u7528\u6570\u5b57\u9012\u5f52\u7b97\u6cd5\uff0c\u7ed3\u5408\u5197\u4f59\u7b97\u672f\u3001\u5728\u7ebf\u5546\u8f6c\u6362\u548c\u64cd\u4f5c\u6570\u7f29\u653e\u7b49\u786c\u4ef6\u4f18\u5316\u6280\u672f\uff0c\u5b9e\u73b0radix-4\u6570\u5b57\u9012\u5f52\u7684posit\u9664\u6cd5\u5355\u5143\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u663e\u8457\u63d0\u5347\uff1a\u80fd\u8017\u964d\u4f4e80%\u4ee5\u4e0a\uff08\u4ec5\u9700\u5c0f\u9762\u79ef\u5f00\u9500\uff09\uff0c\u8fed\u4ee3\u6b21\u6570\u5927\u5e45\u51cf\u5c11\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4f18\u5316\u80fd\u6709\u6548\u63d0\u5347\u57fa\u4e8eposit\u7684\u7b97\u672f\u5355\u5143\u6548\u7387\uff0c\u4e3aposit\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u7684\u9664\u6cd5\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.02530", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.02530", "abs": "https://arxiv.org/abs/2511.02530", "authors": ["Takuto Ando", "Yu Eto", "Yasuhiko Nakashima"], "title": "Implementation and Evaluation of Stable Diffusion on a General-Purpose CGLA Accelerator", "comment": "This paper is accepted at 2025 IEEE 18th International Symposium on\n  Embedded Multicore/Many-core Systems-on-Chip (MCSoC)", "summary": "This paper presents the first implementation and in-depth evaluation of the\nprimary computational kernels from the stable-diffusion.cpp image generation\nframework on IMAX3, a general-purpose Coarse-Grained Reconfigurable Array\n(CGRA) accelerator. We designed IMAX3 as a versatile computational platform,\nand this work assesses its capabilities by executing a demanding image\ngeneration workload. We evaluate its performance on a current\nField-Programmable Gate Array (FPGA) prototype to establish a baseline and\nproject its potential for a future Application-Specific Integrated Circuit\n(ASIC) implementation. Our results demonstrate that, despite its\ngeneral-purpose architecture, IMAX3 achieves promising performance and power\nefficiency, particularly in its projected ASIC form. This work provides\nconcrete guidelines for future IMAX architectural designs and establishes a\nfoundation for developing next-generation, AI-specialized Coarse-Grained Linear\nArray (CGLA) accelerators by refining this versatile platform. Ultimately, this\nachievement contributes to the realization of energy-efficient, on-device,\nmulti-modal AI platforms.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728IMAX3 CGRA\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0\u4e86stable-diffusion.cpp\u56fe\u50cf\u751f\u6210\u6846\u67b6\u7684\u6838\u5fc3\u8ba1\u7b97\u5185\u6838\uff0c\u5e76\u8fdb\u884c\u4e86\u6df1\u5165\u8bc4\u4f30\u3002\u901a\u8fc7FPGA\u539f\u578b\u6d4b\u8bd5\u548cASIC\u5b9e\u73b0\u6f5c\u529b\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u8be5\u901a\u7528\u67b6\u6784\u5728\u6027\u80fd\u548c\u80fd\u6548\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u8bc4\u4f30IMAX3\u4f5c\u4e3a\u901a\u7528\u8ba1\u7b97\u5e73\u53f0\u5728\u6267\u884c\u9ad8\u8981\u6c42\u7684\u56fe\u50cf\u751f\u6210\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u7684\u80fd\u529b\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u4e13\u7528CGLA\u52a0\u901f\u5668\u7684\u5f00\u53d1\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u5728IMAX3 CGRA\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0stable-diffusion.cpp\u7684\u6838\u5fc3\u8ba1\u7b97\u5185\u6838\uff0c\u901a\u8fc7FPGA\u539f\u578b\u5efa\u7acb\u6027\u80fd\u57fa\u7ebf\uff0c\u5e76\u9884\u6d4b\u5176ASIC\u5b9e\u73b0\u7684\u6f5c\u529b\u3002", "result": "\u5c3d\u7ba1\u91c7\u7528\u901a\u7528\u67b6\u6784\uff0cIMAX3\u5728\u6027\u80fd\u548c\u80fd\u6548\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u9884\u671f\u7684ASIC\u5f62\u5f0f\u4e0b\u66f4\u5177\u4f18\u52bf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765IMAX\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u5e76\u4e3a\u5f00\u53d1\u4e0b\u4e00\u4ee3AI\u4e13\u7528CGLA\u52a0\u901f\u5668\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u80fd\u6548\u9ad8\u3001\u8bbe\u5907\u7aef\u7684\u591a\u6a21\u6001AI\u5e73\u53f0\u3002"}}
