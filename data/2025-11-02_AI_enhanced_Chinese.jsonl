{"id": "2510.25958", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.25958", "abs": "https://arxiv.org/abs/2510.25958", "authors": ["Lukas Pfromm", "Alish Kanani", "Harsh Sharma", "Janardhan Rao Doppa", "Partha Pratim Pande", "Umit Y. Ogras"], "title": "CHIPSIM: A Co-Simulation Framework for Deep Learning on Chiplet-Based Systems", "comment": "Accepted at IEEE Open Journal of the Solid-State Circuits Society", "summary": "Due to reduced manufacturing yields, traditional monolithic chips cannot keep\nup with the compute, memory, and communication demands of data-intensive\napplications, such as rapidly growing deep neural network (DNN) models.\nChiplet-based architectures offer a cost-effective and scalable solution by\nintegrating smaller chiplets via a network-on-interposer (NoI). Fast and\naccurate simulation approaches are critical to unlocking this potential, but\nexisting methods lack the required accuracy, speed, and flexibility. To address\nthis need, this work presents CHIPSIM, a comprehensive co-simulation framework\ndesigned for parallel DNN execution on chiplet-based systems. CHIPSIM\nconcurrently models computation and communication, accurately capturing network\ncontention and pipelining effects that conventional simulators overlook.\nFurthermore, it profiles the chiplet and NoI power consumptions at microsecond\ngranularity for precise transient thermal analysis. Extensive evaluations with\nhomogeneous/heterogeneous chiplets and different NoI architectures demonstrate\nthe framework's versatility, up to 340% accuracy improvement, and power/thermal\nanalysis capability.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.26463", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.26463", "abs": "https://arxiv.org/abs/2510.26463", "authors": ["Xiaolin He", "Cenlin Duan", "Yingjie Qi", "Xiao Ma", "Jianlei Yang"], "title": "MIREDO: MIP-Driven Resource-Efficient Dataflow Optimization for Computing-in-Memory Accelerator", "comment": "7 pages, accepted by ASP-DAC 2026", "summary": "Computing-in-Memory (CIM) architectures have emerged as a promising solution\nfor accelerating Deep Neural Networks (DNNs) by mitigating data movement\nbottlenecks. However, realizing the potential of CIM requires specialized\ndataflow optimizations, which are challenged by an expansive design space and\nstrict architectural constraints. Existing optimization approaches often fail\nto fully exploit CIM accelerators, leading to noticeable gaps between\ntheoretical and actual system-level efficiency. To address these limitations,\nwe propose the MIREDO framework, which formulates dataflow optimization as a\nMixed-Integer Programming (MIP) problem. MIREDO introduces a hierarchical\nhardware abstraction coupled with an analytical latency model designed to\naccurately reflect the complex data transfer behaviors within CIM systems. By\njointly modeling workload characteristics, dataflow strategies, and\nCIM-specific constraints, MIREDO systematically navigates the vast design space\nto determine the optimal dataflow configurations. Evaluation results\ndemonstrate that MIREDO significantly enhances performance, achieving up to\n$3.2\\times$ improvement across various DNN models and hardware setups.", "AI": {"tldr": "\u63d0\u51fa\u4e86MIREDO\u6846\u67b6\uff0c\u5c06\u5b58\u5185\u8ba1\u7b97(CIM)\u52a0\u901f\u5668\u7684\u6570\u636e\u6d41\u4f18\u5316\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u786c\u4ef6\u62bd\u8c61\u548c\u5206\u6790\u5ef6\u8fdf\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347DNN\u5728CIM\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684CIM\u6570\u636e\u6d41\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u5229\u7528\u52a0\u901f\u5668\u6f5c\u529b\uff0c\u7406\u8bba\u4e0e\u5b9e\u9645\u7cfb\u7edf\u6548\u7387\u5b58\u5728\u660e\u663e\u5dee\u8ddd\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212(MIP)\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c42\u6b21\u5316\u786c\u4ef6\u62bd\u8c61\u548c\u5206\u6790\u5ef6\u8fdf\u6a21\u578b\uff0c\u8054\u5408\u5efa\u6a21\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u3001\u6570\u636e\u6d41\u7b56\u7565\u548cCIM\u7279\u5b9a\u7ea6\u675f\u3002", "result": "\u5728\u591a\u79cdDNN\u6a21\u578b\u548c\u786c\u4ef6\u914d\u7f6e\u4e0b\uff0cMIREDO\u5b9e\u73b0\u4e86\u6700\u9ad83.2\u500d\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MIREDO\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86CIM\u6570\u636e\u6d41\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u9645\u7cfb\u7edf\u6548\u7387\u3002"}}
